{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Preprocessing\n",
    "\n",
    "This notebooks preprocesses functional MRI images by executing the following processing steps:\n",
    "\n",
    "1. Reorient Images to RAS\n",
    "1. Removal of non-steady state volumes \n",
    "1. Motion Correction with SPM\n",
    "1. Slice-wise Correction with SPM\n",
    "1. Brain Extraction with SPM and FSL\n",
    "1. Temporal Filter with Nilearn\n",
    "1. Two- step coregistration using BBR with FSL, using WM segmentation from SPM\n",
    "1. Spatial Filter (i.e. smoothing) with Nilearn\n",
    "\n",
    "Additional, this workflow also performs:\n",
    " - ACompCor\n",
    " - TCompCor\n",
    " - Artifact Detection\n",
    " - Computes Friston's 24-paramter model for motion parameters\n",
    " \n",
    "**Note:** This notebook requires that the anatomical preprocessing pipeline was already executed and that it's output can be found in the dataset folder under `dataset/derivatives/fmriflows/preproc_anat`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure Requirements\n",
    "\n",
    "The data structure to run this notebook should be according to the BIDS format. Note that the data should be in a session subfolder:\n",
    "\n",
    "    dataset\n",
    "    ├── analysis-func_specs.json\n",
    "    ├── sub-{sub_id}\n",
    "    │   └── ses-{sess_id}\n",
    "    │       └── func\n",
    "    │           ├── sub-{sub_id}_ses-{sess_id}_task-{task_id}_run-{run_id}_bold.nii.gz\n",
    "    └── task-{task_id}_bold.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Specifications\n",
    "\n",
    "This notebook will extract the relevant processing specifications from the `analysis-func_specs.json` file in the dataset folder. In the current setup, they are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join as opj\n",
    "\n",
    "spec_file = opj('/data', 'analysis-func_specs.json')\n",
    "\n",
    "with open(spec_file) as f:\n",
    "    specs = json.load(f)\n",
    "\n",
    "specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to change any of those values manually, overwrite them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subject names\n",
    "subject_list = specs['subject_list']\n",
    "\n",
    "# List of session names\n",
    "session_list = specs['session_list']\n",
    "\n",
    "# List of run names\n",
    "run_list = specs['run_list']\n",
    "\n",
    "# List of task names\n",
    "task_list = specs['task_list']\n",
    "\n",
    "# Mode and width of spatial filter, i.e. Low-Pass, fwhm of 6mm = ['LP', 6]\n",
    "filters_spatial = specs['filters_spatial']\n",
    "\n",
    "# High and low-pass filter to apply, i.e. Low-Pass of 100Hz = [\"None\", 100]\n",
    "filters_temporal = specs['filters_temporal']\n",
    "\n",
    "# Parameters for Artifact Detection\n",
    "art_param = specs['artifact_parameters']\n",
    "norm_threshold = art_param['norm_threshold']\n",
    "zintensity_threshold = art_param['zintensity_threshold']\n",
    "use_differences = [b=='True' for b in art_param['use_differences']]\n",
    "\n",
    "# Requested isometric voxel resolution after coregistration\n",
    "voxel_res = specs['voxel_res']\n",
    "\n",
    "# Reference time point (in ms) required for slice wise correction\n",
    "ref_time = specs['ref_timepoint']\n",
    "\n",
    "# Number of components to extract with ACompCor and TCompCor\n",
    "ncomp = specs['n_confound_comp']\n",
    "\n",
    "# Number of cores to use\n",
    "n_proc = specs['n_parallel_jobs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerating the Workflow\n",
    "\n",
    "To ensure a good overview of the functional preprocessing, the workflow was divided into three subworkflows:\n",
    "\n",
    "1. The Main Workflow, i.e. doing the actual preprocessing\n",
    "2. The Confound Workflow, i.e. computing confound variables\n",
    "3. Visualization Workflow, i.e. visualizating relevant steps for quality control\n",
    "\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os.path import join as opj\n",
    "from nipype import Workflow, Node, IdentityInterface, Function\n",
    "from nipype.interfaces.image import Reorient\n",
    "from nipype.interfaces.spm import SliceTiming, Realign\n",
    "from nipype.interfaces.fsl import FLIRT, MeanImage, BET, BinaryMaths, ExtractROI\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype.algorithms.confounds import ACompCor, TCompCor, NonSteadyStateDetector, FramewiseDisplacement\n",
    "\n",
    "# Specify SPM location\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('/opt/spm12-dev/spm12_mcr/spm/spm12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Execution Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths and names\n",
    "exp_dir = '/data/derivatives'\n",
    "out_dir = 'fmriflows'\n",
    "work_dir = '/workingdir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a subworkflow for the Main Workflow\n",
    "\n",
    "### Implement Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorient anatomical images to RAS\n",
    "reorient = Node(Reorient(orientation='RAS'), name='reorient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection of Non-Steady State volumes\n",
    "nonsteady_detection = Node(NonSteadyStateDetector(), name='nonsteady_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store number of non-steady state volumes in text file\n",
    "def write_to_txt(in_file, n_volumes):\n",
    "    \n",
    "    import numpy as np\n",
    "    out_file = in_file.replace('.nii.gz', '_nss.txt')\n",
    "    np.savetxt(out_file, [n_volumes], fmt='%d')\n",
    "    return out_file\n",
    "\n",
    "write_nss = Node(Function(input_names=['in_file', 'n_volumes'],\n",
    "                          output_names=['out_file'],\n",
    "                          function=write_to_txt),\n",
    "                 name='write_nss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of Non-Steady State volumes\n",
    "nonsteady_removal = Node(ExtractROI(output_type='NIFTI',\n",
    "                                    t_size=-1),\n",
    "                         name='nonsteady_removal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sequence specifications of functional images\n",
    "def get_parameters(task_id):\n",
    "    \n",
    "    import json\n",
    "    import numpy as np\n",
    "    from os.path import join as opj\n",
    "        \n",
    "    func_desc = opj('/data', 'task-%s_bold.json' % task_id)\n",
    "\n",
    "    with open(func_desc) as f:\n",
    "        func_desc = json.load(f)\n",
    "\n",
    "    # Read out relevant parameters\n",
    "    TR = func_desc['RepetitionTime']\n",
    "    slice_order = func_desc['SliceTiming']\n",
    "    nslices = len(slice_order)\n",
    "    time_acquisition = float(TR)-(TR/nslices)\n",
    "    \n",
    "    return TR, slice_order, nslices, time_acquisition\n",
    "\n",
    "getParam = Node(Function(input_names=['task_id'],\n",
    "                         output_names=['TR', 'slice_order',\n",
    "                                       'nslices', 'time_acquisition'],\n",
    "                         function=get_parameters),\n",
    "                name='getParam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct for motion\n",
    "realign = Node(Realign(register_to_mean=True), name='realign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct for slice-wise acquisition\n",
    "slicetime = Node(SliceTiming(ref_slice=ref_time), name='slicetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset TR value after SPM's slice time correction\n",
    "def add_TR_to_file(in_file, TR):\n",
    "    \n",
    "    import nibabel as nb\n",
    "    \n",
    "    # Load image\n",
    "    img = nb.load(in_file)\n",
    "    \n",
    "    # Reset TR\n",
    "    img.header.set_zooms(list(img.header.get_zooms()[:3]) + [TR])\n",
    "    \n",
    "    # Save file\n",
    "    out_file = in_file.replace('.nii', '_TR.nii')\n",
    "    img.to_filename(out_file)\n",
    "    del img\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "reset_TR = Node(Function(input_names=['in_file', 'TR'],\n",
    "                         output_names=['out_file'],\n",
    "                         function=add_TR_to_file),\n",
    "                name='reset_TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove skull signal from functional images\n",
    "bet_func = Node(BET(functional=True,\n",
    "                    mask=True,\n",
    "                    output_type='NIFTI_GZ'),\n",
    "                name='bet_func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes mean image before coregistration\n",
    "bet_mean = Node(MeanImage(dimension='T',\n",
    "                          output_type='NIFTI_GZ'),\n",
    "                name='bet_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-alignment of functional images to anatomical image\n",
    "coreg_pre = Node(FLIRT(dof=6,\n",
    "                       output_type='NIFTI_GZ'),\n",
    "                 name='coreg_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coregistration of functional images to anatomical image with BBR\n",
    "# using WM segmentation\n",
    "coreg_bbr = Node(FLIRT(dof=6,\n",
    "                       cost='bbr',\n",
    "                       schedule=opj(os.getenv('FSLDIR'),\n",
    "                                    'etc/flirtsch/bbr.sch'),\n",
    "                       output_type='NIFTI_GZ'),\n",
    "                 name='coreg_bbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply coregistration warp to functional images\n",
    "applycoreg = Node(FLIRT(interp='spline',\n",
    "                        apply_isoxfm=voxel_res,\n",
    "                        datatype='short',\n",
    "                        output_type='NIFTI_GZ'),\n",
    "                 name='applycoreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop coregistered files to reduce file size\n",
    "def crop_img(in_file, reference, padding=3):\n",
    "\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    from nilearn.image import coord_transform\n",
    "\n",
    "    # Load functional and reference image\n",
    "    func = nb.load(in_file)\n",
    "    ref = nb.load(reference)\n",
    "\n",
    "    # Compute the minimal and maximal MNI coordinate of content\n",
    "    content = np.nonzero(ref.get_fdata())\n",
    "    corner_min = np.array(content).min(axis=1)\n",
    "    corner_max = np.array(content).max(axis=1)\n",
    "    x, y, z = corner_min\n",
    "    min_coord = coord_transform(x, y, z, ref.affine)\n",
    "    x, y, z = corner_max\n",
    "    max_coord = coord_transform(x, y, z, ref.affine)\n",
    "\n",
    "    # Transform min and max coordinates back into functional space.\n",
    "    # Padding value can be used to extend the cut area.\n",
    "    inverse = np.linalg.inv(func.affine)\n",
    "    cut_min = np.dot(inverse, np.hstack((min_coord, 1))\n",
    "                     )[:3].round().astype('int') - padding\n",
    "    cut_max = np.dot(inverse, np.hstack((max_coord, 1))\n",
    "                    )[:3].round().astype('int') + padding\n",
    "\n",
    "    # Make sure that cuts are not outside of volume\n",
    "    cut_min[cut_min < 0] = 0\n",
    "    outside_box = 100+cut_max > func.shape[:3]\n",
    "    cut_max[outside_box] = np.array(func.shape[:3])[outside_box]\n",
    "\n",
    "    # Reduce FOV of functional image accordingly\n",
    "    func = func.slicer[cut_min[0]: cut_max[0],\n",
    "                       cut_min[1]: cut_max[1],\n",
    "                       cut_min[2]: cut_max[2],\n",
    "                       :]\n",
    "    out_file = in_file.replace('.nii', '_crop.nii')\n",
    "    func.to_filename(out_file)\n",
    "    del func\n",
    "\n",
    "    return out_file\n",
    "\n",
    "cropper = Node(Function(input_names=['in_file', 'reference'],\n",
    "                        output_names=['out_file'],\n",
    "                        function=crop_img),\n",
    "               name='cropper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Temporal Filter\n",
    "def apply_temporal_filter(in_file, TR, tFilter):\n",
    "    \n",
    "    import nibabel as nb\n",
    "    from nilearn.image import clean_img, mean_img, math_img\n",
    "    \n",
    "    # Transform cutoff values into HZ\n",
    "    low_pass, high_pass = tFilter\n",
    "    postfix = 'tfilt_%s.%s' % (low_pass, high_pass)\n",
    "    low_pass = 1. / low_pass if low_pass != 'None' else None\n",
    "    high_pass = 1. / high_pass if high_pass != 'None' else None\n",
    "    \n",
    "    out_file = in_file.replace('.nii', '_%s.nii' % postfix)\n",
    "    \n",
    "    # Apply temporal filter and store it in new file\n",
    "    img = clean_img(in_file, detrend=False, standardize=False, t_r=TR,\n",
    "                    ensure_finite=True, low_pass=low_pass, high_pass=high_pass)\n",
    "    affine = img.affine\n",
    "    header = img.header\n",
    "\n",
    "    # Add mean if image was high pass filtered\n",
    "    if high_pass:\n",
    "        img = math_img(\"img1 + img2[...,None]\", img1=img, img2=mean_img(in_file))\n",
    "\n",
    "    # Save temporal filtered image\n",
    "    nb.Nifti1Image(img.get_fdata(), affine, header).to_filename(out_file)\n",
    "    del img\n",
    "\n",
    "    return out_file\n",
    "\n",
    "temporal_filter = Node(Function(input_names=['in_file', 'TR', 'tFilter'],\n",
    "                        output_names=['out_file'],\n",
    "                        function=apply_temporal_filter),\n",
    "               name='temp_filter')\n",
    "temporal_filter.iterables = ('tFilter', filters_temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies gaussian spatial filter as in Sengupta, Pollmann & Hanke, 2018\n",
    "def gaussian_spatial_filter(in_file, sFilter, bandwidth=1):\n",
    "\n",
    "    import nibabel as nb\n",
    "    from nilearn.image import smooth_img\n",
    "\n",
    "    ftype, fwhm = sFilter\n",
    "\n",
    "    if ftype == 'LP':\n",
    "        img = smooth_img(in_file, fwhm=fwhm)\n",
    "        \n",
    "    if ftype == 'HP':\n",
    "        img = nb.load(in_file)\n",
    "        HPF_bold = img.get_data() - smooth_img(in_file, fwhm=fwhm).get_data()\n",
    "        img = nb.Nifti1Image(HPF_bold, img.get_affine())\n",
    "        \n",
    "    elif ftype == 'BP':\n",
    "        LPF_bold_1 = smooth_img(in_file, fwhm=fwhm)\n",
    "        LPF_bold_2 = smooth_img(in_file, fwhm=fwhm - bandwidth)\n",
    "        BPF_bold = LPF_bold_2.get_fdata() - LPF_bold_1.get_fdata()\n",
    "        img = nb.Nifti1Image(BPF_bold, LPF_bold_1.affine, LPF_bold_1.header)\n",
    "        \n",
    "    # Save and return output file\n",
    "    out_file = in_file.replace('.nii', '_%s_%smm.nii' % (ftype, fwhm))\n",
    "    img.to_filename(out_file)\n",
    "    del img\n",
    "\n",
    "    return out_file\n",
    "\n",
    "# Spatial Band-Pass Filter\n",
    "spatial_filter = Node(Function(input_names=['in_file', 'sFilter'],\n",
    "                        output_names=['out_file'],\n",
    "                        function=gaussian_spatial_filter),\n",
    "               name='spatial_filter')\n",
    "spatial_filter.iterables = ('sFilter', filters_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes mean image\n",
    "meanimg = Node(MeanImage(dimension='T',\n",
    "                         output_type='NIFTI_GZ'),\n",
    "               name='meanimg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Main Workflow\n",
    "\n",
    "**Note:** Slice time correction is applied after motion correction, as recommended by Power et al. (2017): http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0182939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main preprocessing workflow\n",
    "mainflow = Workflow(name='mainflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes to workflow and connect them\n",
    "mainflow.connect([(reorient, nonsteady_detection, [('out_file', 'in_file')]),\n",
    "                  (reorient, nonsteady_removal, [('out_file', 'in_file')]),\n",
    "                  (reorient, write_nss, [('out_file', 'in_file')]),\n",
    "                  (nonsteady_detection, write_nss, [('n_volumes_to_discard', 'n_volumes')]),\n",
    "                  (nonsteady_detection, nonsteady_removal, [('n_volumes_to_discard',\n",
    "                                                             't_min')]),\n",
    "                  (nonsteady_removal, realign, [('roi_file', 'in_files')]),\n",
    "                  (realign, slicetime, [('realigned_files', 'in_files')]),\n",
    "                  (getParam, slicetime, [('TR', 'time_repetition'),\n",
    "                                         ('slice_order', 'slice_order'),\n",
    "                                         ('nslices', 'num_slices'),\n",
    "                                         ('time_acquisition', 'time_acquisition'),\n",
    "                                         ]),\n",
    "                  (slicetime, reset_TR, [('timecorrected_files', 'in_file')]),\n",
    "                  (getParam, reset_TR, [('TR', 'TR')]),\n",
    "                  (reset_TR, bet_func, [('out_file', 'in_file')]),\n",
    "                  (bet_func, bet_mean, [('out_file', 'in_file')]),\n",
    "\n",
    "                  # Coregistration\n",
    "                  (coreg_pre, coreg_bbr, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                  (coreg_bbr, applycoreg, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                  (bet_mean, coreg_pre, [('out_file', 'in_file')]),\n",
    "                  (bet_mean, coreg_bbr, [('out_file', 'in_file')]),\n",
    "                  (bet_func, applycoreg, [('out_file', 'in_file')]),\n",
    "                  (applycoreg, cropper, [('out_file', 'in_file')]),\n",
    "                  \n",
    "                  # Apply Temporal and Spatial Filter\n",
    "                  (getParam, temporal_filter, [('TR', 'TR')]),\n",
    "                  (cropper, temporal_filter, [('out_file', 'in_file')]),\n",
    "                  (temporal_filter, spatial_filter, [('out_file', 'in_file')]),\n",
    "                  (cropper, meanimg, [('out_file', 'in_file')]),\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a subworkflow for the Confound Workflow\n",
    "\n",
    "### Implement Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ACompCor (based on Behzadi et al., 2007)\n",
    "aCompCor = Node(ACompCor(num_components=ncomp,\n",
    "                         pre_filter=False,\n",
    "                         save_pre_filter=False,\n",
    "                         merge_method='union',\n",
    "                         components_file='compcorA.txt'),\n",
    "                name='aCompCor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary mask for ACompCor (based on Behzadi et al., 2007)\n",
    "def get_csf_wm_mask(wm, csf, in_file):\n",
    "    \n",
    "    from nibabel import Nifti1Image\n",
    "    from nilearn.image import threshold_img, resample_to_img\n",
    "    from scipy.ndimage.morphology import binary_erosion, binary_closing\n",
    "\n",
    "    # Create eroded WM binary mask\n",
    "    thr_wm = threshold_img(wm, 0.99)\n",
    "    res_wm = resample_to_img(thr_wm, in_file)\n",
    "    bin_wm = threshold_img(res_wm, 0.5)\n",
    "    mask_wm = binary_erosion(bin_wm.get_fdata(), iterations=2).astype('int8')\n",
    "\n",
    "    # Create eroded CSF binary mask (differs from Behzadi et al., 2007)\n",
    "    thr_csf = threshold_img(csf, 0.99)\n",
    "    res_csf = resample_to_img(thr_csf, in_file)\n",
    "    bin_csf = threshold_img(res_csf, 0.5)\n",
    "    close_csf = binary_closing(bin_csf.get_fdata(), iterations=1)\n",
    "    mask_csf = binary_erosion(close_csf, iterations=1).astype('int8')\n",
    "    \n",
    "    # Combine WM and CSF binary masks into one\n",
    "    binary_mask = ((mask_wm + mask_csf) > 0).astype('int8')\n",
    "    out_file = in_file.replace('.nii', '_maskA.nii')\n",
    "    Nifti1Image(binary_mask, res_wm.affine).to_filename(out_file)\n",
    "\n",
    "    return out_file\n",
    "\n",
    "acomp_masks = Node(Function(input_names=['wm', 'csf', 'in_file'],\n",
    "                            output_names=['out_file'],\n",
    "                            function=get_csf_wm_mask),\n",
    "                   name='acomp_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TCompCor (based on Behzadi et al., 2007)\n",
    "tCompCor = Node(TCompCor(num_components=ncomp,\n",
    "                         percentile_threshold=0.02,\n",
    "                         pre_filter=False,\n",
    "                         save_pre_filter=False,\n",
    "                         components_file='compcorT.txt'),\n",
    "                name='tCompCor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary mask for TCompCor approach (based on Behzadi et al., 2007)\n",
    "def get_brainmask(in_file):\n",
    "    \n",
    "    from nibabel import Nifti1Image\n",
    "    from nilearn.image import mean_img\n",
    "    from scipy.ndimage.morphology import binary_erosion\n",
    "    \n",
    "    img = mean_img(in_file)\n",
    "    erod_img = binary_erosion(img.get_fdata()>0, iterations=1).astype('int8')\n",
    "    \n",
    "    out_file = in_file.replace('.nii', '_maskT.nii')\n",
    "    Nifti1Image(erod_img, img.affine).to_filename(out_file)\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "tcomp_brainmask = Node(Function(input_names=['in_file'],\n",
    "                          output_names=['out_file'],\n",
    "                          function=get_brainmask),\n",
    "                 name='tcomp_brainmask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute FramewiseDisplacement\n",
    "FD = Node(FramewiseDisplacement(parameter_source='SPM'),\n",
    "          name='FD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects intensity and motion artifacts and labels them as outliers\n",
    "# Note that a z-threshold of 2.58 corresponds to 99% of normal distributed vales\n",
    "art = Node(ArtifactDetect(norm_threshold=norm_threshold,\n",
    "                          zintensity_threshold=zintensity_threshold,\n",
    "                          mask_type='file',\n",
    "                          parameter_source='SPM',\n",
    "                          use_differences=use_differences,\n",
    "                          plot_type='svg'),\n",
    "           name='art')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes Friston 24-parameter model (Friston et al., 1996)\n",
    "def compute_friston24(in_file):\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    # Load raw motion parameters\n",
    "    mp_raw = np.loadtxt(in_file)\n",
    "    \n",
    "    # Get motion paremter one time point before\n",
    "    mp_minus1 = np.vstack((mp_raw[1:], [0] * 6))\n",
    "    \n",
    "    # Combine the two\n",
    "    mp_combine = np.hstack((mp_raw, mp_minus1))\n",
    "\n",
    "    # Add the square of those parameters to allow correction of nonlinear effects\n",
    "    mp_friston = np.hstack((mp_combine, mp_combine**2))\n",
    "\n",
    "    # Save friston 24-parameter model in new txt file\n",
    "    out_file = in_file.replace('.txt', 'friston24.txt')\n",
    "    np.savetxt(out_file, mp_friston,\n",
    "               fmt='%.8f', delimiter=' ', newline='\\n')\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "friston24 = Node(Function(input_names=['in_file'],\n",
    "                          output_names=['out_file'],\n",
    "                          function=compute_friston24),\n",
    "                 name='friston24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine confound parameters into one TSV file\n",
    "def consolidate(FD, par_rp, par_friston, compA, compT):\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    conf_FD = np.array(list(np.loadtxt(FD, skiprows=1)) + [0])\n",
    "    conf_rp = np.loadtxt(par_rp)\n",
    "    conf_friston = np.loadtxt(par_friston)\n",
    "    conf_compA = np.loadtxt(compA, skiprows=1)\n",
    "    conf_compT = np.loadtxt(compT, skiprows=1)\n",
    "\n",
    "    # Aggregate confounds\n",
    "    confounds = np.hstack((conf_FD[..., None],\n",
    "                           conf_rp,\n",
    "                           conf_friston,\n",
    "                           conf_compA,\n",
    "                           conf_compT))\n",
    "\n",
    "    # Create header\n",
    "    header = ['FD']\n",
    "    header += ['RP%02d' % (d + 1) for d in range(conf_rp.shape[1])]\n",
    "    header += ['Friston%02d' % (d + 1) for d in range(conf_friston.shape[1])]\n",
    "    header += ['CompA%02d' % (d + 1) for d in range(conf_compA.shape[1])]\n",
    "    header += ['CompT%02d' % (d + 1) for d in range(conf_compT.shape[1])]\n",
    "\n",
    "    # Write to file\n",
    "    out_file = par_rp.replace('rp', 'confounds')\n",
    "    out_file = out_file.replace('.txt', '.tsv')\n",
    "    with open(out_file, 'w') as f:\n",
    "        f.write('\\t'.join(header) + '\\n')\n",
    "        for row in confounds:\n",
    "            f.write('\\t'.join([str(r) for r in row]) + '\\n')\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "combine_confounds = Node(Function(input_names=['FD', 'par_rp', 'par_friston',\n",
    "                                               'compA', 'compT'],\n",
    "                                  output_names=['out_file'],\n",
    "                                  function=consolidate),\n",
    "                         name='combine_confounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Confound Correlation Maps\n",
    "def compute_correlation_map(in_file, confounds):\n",
    "\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    from scipy.stats import zscore\n",
    "    \n",
    "    # Load image\n",
    "    img = nb.load(in_file)\n",
    "\n",
    "    # zscore functional data\n",
    "    data = zscore(img.get_fdata(), axis=-1)\n",
    "\n",
    "    # zscore confound parameters\n",
    "    par = zscore(np.loadtxt(confounds, skiprows=1), axis=-1)\n",
    "\n",
    "    # Compute correlation map per component\n",
    "    corr_map = np.nan_to_num(np.dot(data, par))\n",
    "\n",
    "    # Save and return output file\n",
    "    img = nb.Nifti1Image(corr_map, img.affine, img.header)\n",
    "    out_file = in_file.replace('.nii', '_confounds_map.nii')\n",
    "    img.to_filename(out_file)\n",
    "    del img, data\n",
    "\n",
    "    return out_file\n",
    "\n",
    "comp_corr_map = Node(Function(input_names=['in_file', 'confounds'],\n",
    "                              output_names=['out_file'],\n",
    "                              function=compute_correlation_map),\n",
    "                     name='comp_corr_map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Confound Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confound extraction workflow\n",
    "confflow = Workflow(name='confflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes to workflow and connect them\n",
    "confflow.connect([(acomp_masks, aCompCor, [('out_file', 'mask_files')]),\n",
    "                  (tcomp_brainmask, tCompCor, [('out_file', 'mask_files')]),\n",
    "\n",
    "                  # Consolidate confounds\n",
    "                  (FD, combine_confounds, [('out_file', 'FD')]),\n",
    "                  (aCompCor, combine_confounds, [('components_file', 'compA')]),\n",
    "                  (tCompCor, combine_confounds, [('components_file', 'compT')]),\n",
    "                  (friston24, combine_confounds, [('out_file', 'par_friston')]),\n",
    "                  \n",
    "                  # Compute functional correlation map\n",
    "                  (combine_confounds, comp_corr_map, [('out_file', 'confounds')]),\n",
    "                  ])\n",
    "confflow.add_nodes([art])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Input & Output Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over subject, session, task and run id\n",
    "infosource = Node(IdentityInterface(fields=['subject_id', 'session_id',\n",
    "                                            'task_id', 'run_id']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subject_id', subject_list),\n",
    "                        ('session_id', session_list),\n",
    "                        ('task_id', task_list),\n",
    "                        ('run_id', run_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input file location\n",
    "templates = {'anat':  opj('fmriflows', 'preproc_anat', 'sub-{subject_id}',\n",
    "                          'ses-{session_id}_brain.nii.gz'),\n",
    "             'wm':  opj('fmriflows', 'preproc_anat', 'sub-{subject_id}',\n",
    "                        'ses-{session_id}_seg_wm.nii'),\n",
    "             'csf':  opj('fmriflows', 'preproc_anat', 'sub-{subject_id}',\n",
    "                         'ses-{session_id}_seg_csf.nii'),\n",
    "             'func':  opj('/data', 'sub-{subject_id}', 'ses-{session_id}', 'func',\n",
    "                          'sub-{subject_id}_ses-{session_id}_task-{task_id}_run-{run_id}_bold.nii.gz')}\n",
    "\n",
    "sf = Node(SelectFiles(templates,\n",
    "                      base_directory=exp_dir,\n",
    "                      sort_filelist=True),\n",
    "          name='selectfiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save relevant outputs in a datasink\n",
    "datasink = Node(DataSink(base_directory=exp_dir,\n",
    "                         container=out_dir),\n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following naming substitutions for the datasink\n",
    "substitutions = [(\n",
    "    '_run_id_%s_session_id_%s_subject_id_%s_task_id_%s/' % (run, sess, sub, task),\n",
    "    'sub-%s/task-%s_ses-%s_run-%s_' % (sub, task, sess, run))\n",
    "    for sub in subject_list\n",
    "    for sess in session_list\n",
    "    for run in run_list\n",
    "    for task in task_list]\n",
    "substitutions += [\n",
    "    ('sub-%s_ses-%s_task-%s_run-%s_bold' % (sub, sess, task, run), '')\n",
    "    for sub in subject_list\n",
    "    for sess in session_list\n",
    "    for run in run_list\n",
    "    for task in task_list]\n",
    "substitutions += [('_tFilter_%s.%s/' % (t[0], t[1]), '')\n",
    "                  for t in filters_temporal]\n",
    "substitutions += [('_sFilter_%s.%s/' % (s[0], s[1]), '')\n",
    "                  for s in filters_spatial]\n",
    "substitutions += [('%s_%smm' % (s[0], s[1]),\n",
    "                   'sFilter_%s_%smm' % (s[0], s[1]))\n",
    "                  for s in filters_spatial]\n",
    "substitutions += [('ar_', ''),\n",
    "                  ('ras_', ''),\n",
    "                  ('roi_', ''),\n",
    "                  ('TR_', ''),\n",
    "                  ('brain_', ''),\n",
    "                  ('flirt_', ''),\n",
    "                  ('crop_', ''),\n",
    "                  ('tfilt', 'tFilter'),\n",
    "                  ('mask_000', 'maskT'),\n",
    "                  ('art.r_', ''),\n",
    "                  ('_roi', '_'),\n",
    "                  ('__', '_'),\n",
    "                  ('_.', '.'),\n",
    "                  ('.r.', '.'),\n",
    "                  ]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Implement Functional Preprocessing Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functional preprocessing workflow\n",
    "preproc_func = Workflow(name='preproc_func')\n",
    "preproc_func.base_dir = work_dir\n",
    "\n",
    "# Connect input nodes to each other\n",
    "preproc_func.connect([(infosource, sf, [('subject_id', 'subject_id'),\n",
    "                                        ('session_id', 'session_id'),\n",
    "                                        ('task_id', 'task_id'),\n",
    "                                        ('run_id', 'run_id')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add input and output nodes and connect them to the main workflow\n",
    "preproc_func.connect([(infosource, mainflow, [('task_id', 'getParam.task_id')]),\n",
    "                      (sf, mainflow, [('func', 'reorient.in_file'),\n",
    "                                      ('anat', 'coreg_pre.reference'),\n",
    "                                      ('anat', 'coreg_bbr.reference'),\n",
    "                                      ('wm', 'coreg_bbr.wm_seg'),\n",
    "                                      ('anat', 'applycoreg.reference'),\n",
    "                                      ('anat', 'cropper.reference')]),\n",
    "                      \n",
    "                      (mainflow, datasink, [\n",
    "                          ('spatial_filter.out_file', 'preproc_func.@func'),\n",
    "                          ('meanimg.out_file', 'preproc_func.@mean'),\n",
    "                          ('write_nss.out_file', 'preproc_func.@nss')]),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add input and output nodes and connect them to the confound workflow\n",
    "preproc_func.connect([(sf, confflow, [('wm', 'acomp_masks.wm'),\n",
    "                                      ('csf', 'acomp_masks.csf')]),\n",
    "\n",
    "                      (confflow, datasink, [\n",
    "                          ('art.outlier_files', 'preproc_func.@outlier_files'),\n",
    "                          ('art.plot_files', 'preproc_func.@outlier_plot'),\n",
    "                          ('tCompCor.high_variance_masks', 'preproc_func.@maskT'),\n",
    "                          ('acomp_masks.out_file', 'preproc_func.@maskA'),\n",
    "                          ('combine_confounds.out_file', 'preproc_func.@confound_tsv'),\n",
    "                          ('comp_corr_map.out_file', 'preproc_func.@confound_map')\n",
    "                      ]),\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Connect main workflow with confound workflow\n",
    "preproc_func.connect([(mainflow, confflow, [\n",
    "                          ('getParam.TR', 'aCompCor.repetition_time'),\n",
    "                          ('cropper.out_file', 'aCompCor.realigned_file'),\n",
    "                          ('cropper.out_file', 'acomp_masks.in_file'),\n",
    "                          ('getParam.TR', 'tCompCor.repetition_time'),\n",
    "                          ('cropper.out_file', 'tCompCor.realigned_file'),\n",
    "                          ('cropper.out_file', 'tcomp_brainmask.in_file'),\n",
    "                          ('cropper.out_file', 'comp_corr_map.in_file'),\n",
    "                          ('realign.realigned_files', 'art.realigned_files'),\n",
    "                          ('realign.realignment_parameters', 'art.realignment_parameters'),\n",
    "                          ('realign.realignment_parameters', 'combine_confounds.par_rp'),\n",
    "                          ('realign.realignment_parameters', 'friston24.in_file'),\n",
    "                          ('bet_func.mask_file', 'art.mask_file'),\n",
    "                          ('realign.realignment_parameters', 'FD.in_file'),\n",
    "                          ('getParam.TR', 'FD.series_tr'),\n",
    "                          ])\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create preproc_func output graph\n",
    "preproc_func.write_graph(graph2use='colored', format='svg', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import SVG\n",
    "SVG(filename=opj(preproc_func.base_dir, 'preproc_func', 'graph.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the workflow in parallel mode\n",
    "preproc_func.run(plugin='MultiProc', plugin_args={'n_procs' : n_proc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save workflow graph visualizations in datasink\n",
    "preproc_func.write_graph(graph2use='flat', format='svg', simple_form=True)\n",
    "preproc_func.write_graph(graph2use='colored', format='svg', simple_form=True)\n",
    "\n",
    "from shutil import copyfile\n",
    "copyfile(opj(preproc_func.base_dir, 'preproc_func', 'graph.svg'),\n",
    "         opj(exp_dir, out_dir, 'preproc_func', 'graph.svg'))\n",
    "copyfile(opj(preproc_func.base_dir, 'preproc_func', 'graph_detailed.svg'),\n",
    "         opj(exp_dir, out_dir, 'preproc_func', 'graph_detailed.svg'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP: To show possible outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = subject_list[0]\n",
    "sess = session_list[0]\n",
    "run = run_list[0]\n",
    "task = task_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, create title for output figures\n",
    "title_txt = 'Sub: %s - Task: %s - Sess: %s - Run: %s' % (sub, task, sess, run)\n",
    "title_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilearn.image import coord_transform\n",
    "\n",
    "# Support Function to get optimal cut for visualization\n",
    "def get_cut_ids(img, axis=0):\n",
    "\n",
    "    # Compute voxel id to cut\n",
    "    idx = np.sort(img.get_fdata().nonzero()[axis])\n",
    "    vox_id = np.linspace(idx.min(), idx.max(), num=12, endpoint=True).astype('int')\n",
    "    vox_id = vox_id[2:-2]\n",
    "\n",
    "    # Translate voxel id to image space\n",
    "    if axis == 0:\n",
    "        cut_ids = [int(coord_transform(r, 0, 0, img.affine)[0]) for r in vox_id]\n",
    "    elif axis == 1:\n",
    "        cut_ids = [int(coord_transform(0, r, 0, img.affine)[1]) for r in vox_id]\n",
    "    elif axis == 2:\n",
    "        cut_ids = [int(coord_transform(0, 0, r, img.affine)[2]) for r in vox_id]\n",
    "    return cut_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay Mean functional (after co-registration) and CompCor masks on anatomy\n",
    "\n",
    "This plot should help to investigate the co-registration (grey outlienes of functional mean) and shows which voxels are included in the temporal (yellow) and anatomical (blue) CompCor mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat = '/data/derivatives/fmriflows/preproc_anat/sub-%s/ses-%s_T1w_corrected.nii.gz' % (sub, sess)\n",
    "mean = '/data/derivatives/fmriflows/preproc_func/sub-%s/task-%s_ses-%s_run-%s_mean.nii.gz' % (sub, task, sess, run)\n",
    "maskA = '/data/derivatives/fmriflows/preproc_func/sub-%s/task-%s_ses-%s_run-%s_maskA.nii.gz' % (sub, task, sess, run)\n",
    "maskT = '/data/derivatives/fmriflows/preproc_func/sub-%s/task-%s_ses-%s_run-%s_maskT.nii.gz' % (sub, task, sess, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "from matplotlib.pyplot import figure\n",
    "from nilearn.plotting import plot_anat\n",
    "\n",
    "# Visualize preprocessed functional mean on subject anatomy\n",
    "def plot_mean(anat, mean, maksA, maskT, title):\n",
    "    fig = figure(figsize=(16, 8))\n",
    "    \n",
    "    for i, e in enumerate(['x', 'y', 'z']):\n",
    "        ax = fig.add_subplot(3, 1, i + 1)\n",
    "        \n",
    "        display = plot_anat(anat, title=title_txt + ' - %s-axis' % e, colorbar=False,\n",
    "                            display_mode=e, cut_coords=get_cut_ids(nb.load(mean), i),\n",
    "                            annotate=False, axes=ax)\n",
    "        display.add_edges(mean, color='lightgrey')\n",
    "        display.add_contours(maskA, filled=True, cmap='cool_r',\n",
    "                             resampling_interpolation='nearest')\n",
    "        display.add_contours(maskT, filled=True, cmap='Wistia_r',\n",
    "                             resampling_interpolation='nearest')\n",
    "    out_file = mean.replace('_mean.nii.gz', '_overlays.svg')\n",
    "    fig.savefig(out_file, bbox_inches='tight', facecolor='black', frameon=True,\n",
    "                dpi=300, transparent=True)\n",
    "\n",
    "plot_mean(anat, mean, maskA, maskT, title_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot artifact detection output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "art = '/data/derivatives/fmriflows/preproc_func/sub-%s/task-%s_ses-%s_run-%s_plot.svg' % (sub, task, sess, run)\n",
    "SVG(filename=art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot carpet plot\n",
    "\n",
    "From fmriprep: \"Summary statistics are plotted, which may reveal trends or artifacts in the BOLD data. Global signals calculated within the whole-brain (GS), within the white-matter (WM) and within cerebro-spinal fluid (CSF) show the mean BOLD signal in their corresponding masks. DVARS and FD show the standardized DVARS and framewise-displacement measures for each time point.<br />A carpet plot shows the time series for all voxels within the brain mask. Voxels are grouped into cortical (blue), and subcortical (orange) gray matter, cerebellum (green) and white matter and CSF (red), indicated by the color map on the left-hand side.\"\n",
    "\n",
    "I wanted to look into this, but a quick try didn't really work. I'm not sure if we can create such a carpet plot with GM, WM and CSF segments or if we really need an atlas. If so, than we can use the script `/templates/parcellate_HarvardOxford.py` to create HarvardOxford atlas ROIs with a desired voxel resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds = '/data/derivatives/fmriflows/preproc_func/sub-%s/task-%s_ses-%s_run-%s_confounds.tsv' % (sub, task, sess, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confound parameters\n",
    "def plot_confound_parameters(confounds, title):\n",
    "\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    sns.set(context='notebook', style='darkgrid')\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Load confound signal and header\n",
    "    signal = np.loadtxt(confounds, skiprows=1)\n",
    "    with open(confounds, 'r') as f:\n",
    "        header = f.readlines()[0][:-1].split('\\t')\n",
    "\n",
    "    # Plot and save Framewise Displacement\n",
    "    fig = figure(figsize=(12, 2))\n",
    "    plt.title('FD')\n",
    "    plt.plot(signal[:, 0])\n",
    "    plt.ylabel(header[0])\n",
    "    plt.xlabel('Time [in #TR]')\n",
    "    plt.tight_layout()\n",
    "    out_file = confounds.replace('.tsv','_FD.svg')\n",
    "    fig.savefig(out_file)\n",
    "    fig.clf()\n",
    "        \n",
    "    # Specify plotting groups\n",
    "    groups = {'Motion': [1, 6],\n",
    "              'Friston24': [7, 24],\n",
    "              'CompCorA': [31, 6],\n",
    "              'CompCorT': [37, 6]}\n",
    "    \n",
    "    for g in groups:\n",
    "        \n",
    "        cut = groups[g]\n",
    "        conf = signal[:, cut[0]:cut[0] + cut[1]]\n",
    "        head = header[cut[0]:cut[0] + cut[1]]\n",
    "        nConf = conf.shape[-1]\n",
    "    \n",
    "        fig, axes = plt.subplots(nConf, 1, figsize=(12, nConf * 2))\n",
    "        axes[0].set_title(g)\n",
    "        for i in range(nConf):\n",
    "            axes[i].plot(conf[:, i])\n",
    "            axes[i].set_ylabel(head[i])\n",
    "        axes[i].set_xlabel('Time [in #TR]')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save output\n",
    "        out_file = confounds.replace('.tsv','_%s.svg' % g)\n",
    "        fig.savefig(out_file)\n",
    "        fig.clf()\n",
    "    \n",
    "plot_confound_parameters(confounds, title_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confound correlation maps\n",
    "\n",
    "Here I take the correlation maps from the motion, friston24, compcorA and compcorT confounds and compute the maximum correlation per voxel and plot it on the anatomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat = '/data/derivatives/fmriflows/preproc_anat/sub-%s/ses-%s_T1w_corrected.nii.gz' % (sub, sess)\n",
    "corr_map = '/data/derivatives/fmriflows/preproc_func/sub-%s/task-%s_ses-%s_run-%s_confounds_map.nii.gz' % (sub, task, sess, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confound correlation maps\n",
    "def plot_confounds(anat, corr_map, title):\n",
    "\n",
    "    import nibabel as nb\n",
    "    from matplotlib.pyplot import figure\n",
    "    from nilearn.plotting import plot_stat_map\n",
    "    \n",
    "    # Load correlation map\n",
    "    corr = nb.load(corr_map)\n",
    "    \n",
    "    # Specify plotting groups\n",
    "    groups = {'Motion': [1, 6],\n",
    "              'Friston24': [7, 24],\n",
    "              'CompCorA': [31, 6],\n",
    "              'CompCorT': [37, 6]}\n",
    "   \n",
    "    for g in groups:\n",
    "        \n",
    "        cut = groups[g]\n",
    "        conf = corr.slicer[..., cut[0]:cut[0] + cut[1]]\n",
    "        max_corr = np.max(np.abs(conf.get_fdata()), axis=-1)\n",
    "        max_conf = nb.Nifti1Image(max_corr, conf.affine, conf.header)\n",
    "\n",
    "        fig = figure(figsize=(16, 8))\n",
    "        for i, e in enumerate(['x', 'y', 'z']):\n",
    "            ax = fig.add_subplot(3, 1, i + 1)\n",
    "\n",
    "            thr = max_conf.get_fdata().max() * 0.50\n",
    "            \n",
    "            plot_stat_map(max_conf, title=title_txt + ' - %s' % g, colorbar=False,\n",
    "                      threshold=thr, bg_img=anat, display_mode=e,\n",
    "                      resampling_interpolation='nearest',\n",
    "                      cut_coords=get_cut_ids(max_conf, i),\n",
    "                      cmap='magma', annotate=False, axes=ax)\n",
    "            \n",
    "        out_file = corr_map.replace('.nii.gz', '_%s.svg' % g)\n",
    "        fig.savefig(out_file, bbox_inches='tight', facecolor='black', frameon=True,\n",
    "                    dpi=300, transparent=True)\n",
    "\n",
    "plot_confounds(anat, corr_map, title_txt)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
