{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"left\"><img width=\"40%\" src=\"templates/logo_fmriflows.png\"></div>\n",
    "\n",
    "# Welcome to fMRIflows\n",
    "\n",
    "fMRIflows is a consortium of many (dependent) fMRI analysis pipelines, including anatomical and functional pre-processing, univariate 1st and 2nd-level analysis, as well as multivariate pattern analysis.\n",
    "\n",
    "This notebook will help you to setup the JSON specification files to run the individual analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of the dataset\n",
    "\n",
    "First, let's see what we've got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids.layout import BIDSLayout\n",
    "layout = BIDSLayout(\"/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = layout.get_subjects()\n",
    "subject_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modalities in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = layout.get_modalities()\n",
    "modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_anat = layout.get_types(modality='anat')\n",
    "modality_anat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_func = layout.get_types(modality='func')\n",
    "modality_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_list = layout.get_sessions()\n",
    "session_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = layout.get_runs()\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = layout.get_tasks()\n",
    "task_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get information, such as **TR** and **voxel resolution** of functional images, let's collect the metadata from the functional images of all subjects (of the first task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of functional images\n",
    "func_files = layout.get(modality='func', return_type='file', type='bold', task=task_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's collect TR and voxel resolution of all functional images (of first task), overall subjects, sessions and runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "\n",
    "resolution = np.array([nb.load(f).header.get_zooms() for f in func_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get median TR of all collected functional images\n",
    "TR = np.median(resolution[:, 3])\n",
    "TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average voxel resolution of all collected functional images\n",
    "vox_res = [round(r, 3) for r in np.mean(resolution[:, :3], axis=0)]\n",
    "vox_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifications for preprocessing workflows\n",
    "\n",
    "Now that we know the content of our dataset, let's write the specification file for the anatomical and functional preprocessing workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification for the anatomical preprocessing workflow\n",
    "\n",
    "For the anatomical preprocessing workflow, we need only a few parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary\n",
    "content_anat = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subject identifiers\n",
    "content_anat['subject_list_anat'] = subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of session identifiers\n",
    "content_anat['session_list_anat'] = session_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T1w image identifier (default: T1w)\n",
    "content_anat['T1w_id'] = 'T1w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voxel resolution of reference template \n",
    "content_anat['res_norm'] = [1.0, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should ANTs Normalization a 'fast' or a 'precise' normalization (default: 'precise')\n",
    "content_anat['norm_accuracy'] = 'precise'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that everything is as we want it, let's plot the parameters for the anatomical preprocessing pipeline again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_anat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification for the functional preprocessing workflow\n",
    "\n",
    "For the functional preprocessing workflow, we need a few more parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary\n",
    "content_func = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subject identifiers\n",
    "content_func['subject_list_func'] = subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of session identifiers\n",
    "content_func['session_list_func'] = session_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of task identifiers\n",
    "content_func['task_list'] = task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of run identifiers\n",
    "content_func['run_list'] = runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference timepoint for slice time correction (in ms)\n",
    "content_func['ref_timepoint'] = int(round((TR * 1000.) / 2.0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isometric voxel resolution for the normalization of the functional images\n",
    "content_func['res_func'] = round(np.median(vox_res).astype('float64'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of spatial filters (smoothing) to apply (separetely, i.e. with iterables)\n",
    "# Values are given in mm\n",
    "content_func['filters_spatial'] = [[\"LP\", 3. * content_func['res_func']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of temporal filters to apply (separetely, i.e. with iterables)\n",
    "# Values are given in seconds\n",
    "content_func['filters_temporal'] = [[None, 100.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the confound sub-workflow, we need to specify the **number of `CompCor` components** that should be computed, the **thresholds** to detect **outliers** in `FD`, `DVARS`, `TV`, `GM`, `WM`, `CSF`, as well as the number of **independent components** that should be extracted from the preprocessed signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of CompCor components to compute\n",
    "content_func['n_compcor_confounds'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for outlier detection (3.27 represents a threshold of 99.9%)\n",
    "content_func['outlier_thresholds'] = [3.27, 3.27, 3.27, 3.27, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of independent components to compute\n",
    "content_func['n_independent_components'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that everything is as we want it, let's plot the parameters for the functional preprocessing pipeline again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the `JSON` specification file\n",
    "\n",
    "We will be using one common `JSON` file for the specifications for the anatomical and functional preprocessing pipelines. The creation of this file is rather simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {}\n",
    "content.update(content_anat)\n",
    "content.update(content_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing that we're still missing is the number of parallel processes that we want to allow during the execution of the preprocessing workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of parallel jops to use during the preprocessing\n",
    "import multiprocessing\n",
    "n_proc = multiprocessing.cpu_count() - 1\n",
    "n_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content['n_parallel_jobs'] = n_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to write the `content` to a `JSON` file. By default the filename is `fmriflows_spec_preproc.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_id = 'fmriflows_spec_preproc'\n",
    "with open('/data/%s.json' % file_id, 'w') as f:\n",
    "    json.dump(content, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifications for 1st-level analysis Workflows\n",
    "\n",
    "After the anatomical and functional preprocessing pipelines were run, we can move on to the 1st-level univariate and multivariate analysis. For this we need to get the different conditions and corresponding contrasts, for each task.\n",
    "\n",
    "## Exploration of the dataset\n",
    "\n",
    "So let's explore the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary\n",
    "content_analysis = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_analysis['tasks'] = {}\n",
    "\n",
    "for t in task_id:\n",
    "    \n",
    "    # Collect first event file of a given task\n",
    "    event_file = layout.get(return_type='file', type='events', task=t)[0]\n",
    "    \n",
    "    # Collect unique condition names\n",
    "    import pandas as pd\n",
    "    df = pd.read_table(event_file)\n",
    "    condition_names = [str(c) for c in np.unique(df['condition'])]\n",
    "    \n",
    "    # Create contrasts (unique and versus rest)\n",
    "    contrasts = []\n",
    "    \n",
    "    # Adding unique contrasts, i.e. [1, 0, 0, 0, ...]\n",
    "    eye_matrix = np.eye(len(condition_names)).tolist()\n",
    "    contrasts += [[c, eye_matrix[i], 'T'] for i, c in enumerate(condition_names)]\n",
    "    \n",
    "    # Add one vs. rest contrasts, i.e. [1, -0.25, -0.25, -0.25, -0.25]\n",
    "    rest_matrix = np.copy(eye_matrix)\n",
    "    rest_matrix[rest_matrix==0] = np.round(-1./(len(condition_names) - 1), 4)\n",
    "    contrasts += [['%s_vs_rest' % c, rest_matrix[i].tolist(), 'T']\n",
    "                  for i, c in enumerate(condition_names)]\n",
    "\n",
    "    # Store the task specific information in a dictionray\n",
    "    content_task = {}\n",
    "    content_task['condition_names'] = condition_names\n",
    "    \n",
    "    # Add contrasts to task dictionary\n",
    "    content_task['contrasts'] = contrasts\n",
    "    \n",
    "    # Store everything ini the analysis dictionary\n",
    "    content_analysis['tasks'][t] = content_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what do we have so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(content_analysis['tasks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to add some additional contrasts, either add them to `content_analysis['tasks'][task_id]['contrasts']` or directly adapt the content of the `fmriflows_spec_analysis.json` file, once this section was excecuted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify additional 1st-level analysis parameters\n",
    "\n",
    "The next section specifies additional model parameters. The assumption is that all different tasks will use those same parameters. If this is not the case, specify multiple `fmriflows_spec_analysis.json` files and run them individually in the `03_analysis_1st-level` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subject identifiers\n",
    "content_analysis['subject_list'] = subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of session identifiers\n",
    "content_analysis['session_list'] = session_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of spatial filters (smoothing) that were used during functional preprocessing\n",
    "content_analysis['filters_spatial'] = content_func['filters_spatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of temporal filters that were used during functional preprocessing\n",
    "content_analysis['filters_temporal'] = content_func['filters_temporal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuisance identifiers that should be included in the GLM\n",
    "content_analysis['nuisance_regressors'] = ['Rotation', 'Translation', 'FD', 'DVARS', 'TV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If outliers detected during functional preprocing should be used in GLM\n",
    "content_analysis['use_outliers'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial Correlation Model to use: 'AR(1)', 'FAST' or 'none'\n",
    "content_analysis['model_serial_correlations'] = 'AR(1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model bases to use: 'hrf', 'fourier', 'fourier', 'fourier_han', 'gamma' or 'fir'\n",
    "# If 'hrf', also specify if time and dispersion derivatives should be used\n",
    "content_analysis['model_bases'] = {'hrf': {'derivs': [1, 0]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation Method to use: 'Classical', 'Bayesian' or 'Bayesian2'\n",
    "content_analysis['estimation_method'] = {'Classical': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify if contrasts should be normalized to template space after estimation\n",
    "content_analysis['normalize'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify voxel resolution of normalized contrasts\n",
    "content_analysis['norm_res'] = [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify if a contrast should be computed for stimuli category per run\n",
    "content_analysis['con_per_run'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify voxel resolution of normalized contrasts for multivariate analysis\n",
    "content_analysis['norm_res_multi'] = [2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a particular analysis postfix\n",
    "content_analysis['analysis_postfix'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of parallel jops to use during the preprocessing\n",
    "import multiprocessing\n",
    "n_proc = multiprocessing.cpu_count() - 1\n",
    "content_analysis['n_parallel_jobs'] = n_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the `JSON` specification file\n",
    "\n",
    "As in the preprocessing example, we will be using one common `JSON` file for the specifications of the 1st-level and 2nd-level analysis. The creation of this file is as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_id = 'fmriflows_spec_analysis'\n",
    "with open('/data/%s.json' % file_id, 'w') as f:\n",
    "    json.dump(content_analysis, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
