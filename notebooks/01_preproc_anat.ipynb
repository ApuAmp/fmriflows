{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Anatomical Preprocessing\n",
    "\n",
    "This notebooks preprocesses anatomical MRI images by executing the following processing steps:\n",
    "\n",
    "1. Reorient Images to RAS\n",
    "1. Crop FOV with FSL\n",
    "1. N4-inhomogenity correction with ANTS\n",
    "1. GM, WM and CSF Segmentation with SPM\n",
    "1. Brainmask creation and Brain extraction with FSL\n",
    "1. Normalization to ICBM template with ANTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Structure Requirements\n",
    "\n",
    "The data structure to run this notebook should be according to the BIDS format. Note that the data should be in a session subfolder:\n",
    "\n",
    "    dataset\n",
    "    ├── analysis-anat_specs.json\n",
    "    └── sub-{sub_id}\n",
    "        └── ses-{sess_id}\n",
    "            └── anat\n",
    "                └── sub-{sub_id}_ses-{sess_id}_{T1_id}.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Execution Specifications\n",
    "\n",
    "This notebook will extract the relevant processing specifications from the `analysis-anat_specs.json` file in the dataset folder. In the current setup, they are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join as opj\n",
    "\n",
    "spec_file = opj('/data', 'analysis-anat_specs.json')\n",
    "\n",
    "with open(spec_file) as f:\n",
    "    specs = json.load(f)\n",
    "\n",
    "specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to change any of those values manually, overwrite them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subject names\n",
    "subject_list = specs['subject_list']\n",
    "\n",
    "# List of session names\n",
    "session_list = specs['session_list']\n",
    "\n",
    "# Anatomical image identifier\n",
    "T1_id = specs['T1_id']\n",
    "\n",
    "# Number of parallel jobs to run\n",
    "n_proc = specs['n_parallel_jobs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Workflow\n",
    "\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as opj\n",
    "from nipype import Workflow, Node, Function, IdentityInterface\n",
    "from nipype.interfaces.image import Reorient\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection, Registration\n",
    "from nipype.interfaces.spm import NewSegment\n",
    "from nipype.interfaces.fsl import ImageMaths, RobustFOV\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "\n",
    "# Specify SPM location\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('/opt/spm12-dev/spm12_mcr/spm/spm12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Execution Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths and names\n",
    "exp_dir = '/data/derivatives'\n",
    "out_dir = 'fmriflows'\n",
    "work_dir = '/output'\n",
    "\n",
    "# Location of template brains\n",
    "template_dir = '/templates/mni_icbm152_nlin_asym_09c/'\n",
    "brain_template = opj(template_dir, '1.0mm_brain.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorient anatomical images to RAS\n",
    "reorient = Node(Reorient(orientation='RAS'), name='reorient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduces FOV of images to remove lower head and neck\n",
    "cropFOV = Node(RobustFOV(output_type='NIFTI_GZ'), name='cropFOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrects bias field\n",
    "n4 = Node(N4BiasFieldCorrection(dimension=3), name='n4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gunzips images\n",
    "gunzip = Node(Gunzip(), name='gunzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segments brain into 5 classes (GM, WM, CSF, Skull & Head)\n",
    "segment = Node(NewSegment(), name='segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create brainmask from GM, WM & CSF segmentation\n",
    "def get_class0(segment_list):\n",
    "    return segment_list[0][0]\n",
    "\n",
    "def get_additional_args(segment_list):\n",
    "    class_1_and_2 = tuple([s[0] for s in segment_list[1:3]])\n",
    "    return '-add %s -add %s -thr 0.95 -bin' % class_1_and_2\n",
    "\n",
    "brainmask = Node(ImageMaths(), name='brainmask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improves brainmask by 1 x erosion, 3 x dilation & filling remaining wholes\n",
    "def correct_mask(in_file):\n",
    "    \n",
    "    import nibabel as nb\n",
    "    from scipy.ndimage.morphology import (\n",
    "        binary_fill_holes, binary_dilation, binary_erosion)\n",
    "    \n",
    "    img = nb.load(in_file)\n",
    "    data = img.get_fdata()\n",
    "    \n",
    "    data_mask = binary_fill_holes(\n",
    "        binary_dilation(binary_erosion(\n",
    "            binary_fill_holes(data), iterations = 1),\n",
    "                        iterations = 3)).astype('int8')\n",
    "    new_img = nb.Nifti1Image(data_mask, img.affine)\n",
    "    out_file = in_file.replace('.nii', '_dil.nii')\n",
    "    new_img.to_filename(out_file)\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "correct_mask = Node(Function(input_names=['in_file'],\n",
    "                             output_names=['out_file'],\n",
    "                             function=correct_mask),\n",
    "                    name='correct_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply brainmask to anatomy to extract brain\n",
    "extract_brain = Node(ImageMaths(op_string='-mul'), name='extract_brain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize anatomy to ICBM template\n",
    "antsreg = Node(Registration(fixed_image=brain_template,\n",
    "                            num_threads=n_proc,\n",
    "                            output_inverse_warped_image=True,\n",
    "                            output_warped_image=True,\n",
    "\n",
    "                            collapse_output_transforms=True,\n",
    "                            dimension=3,\n",
    "                            float=True,\n",
    "                            initial_moving_transform_com=True,\n",
    "                            initialize_transforms_per_stage=False,\n",
    "                            interpolation='LanczosWindowedSinc',\n",
    "                            transforms=['Rigid', 'Affine', 'SyN'],\n",
    "                            transform_parameters=[(0.05,), (0.08,),\n",
    "                                                  (0.1, 3.0, 0.0)],\n",
    "\n",
    "                            metric=['Mattes', 'Mattes', 'CC'],\n",
    "                            metric_weight=[1.0] * 3,\n",
    "                            radius_or_number_of_bins=[56, 56, 4],\n",
    "                            sampling_strategy=['Regular', 'Regular', 'None'],\n",
    "                            sampling_percentage=[0.25, 0.25, 1],\n",
    "                            number_of_iterations=[[100, 100],\n",
    "                                                  [100, 100],\n",
    "                                                  [100, 50, 20, 10]],\n",
    "                            convergence_threshold=[1e-06] * 3,\n",
    "                            convergence_window_size=[20, 20, 10],\n",
    "                            smoothing_sigmas=[[2, 1], [1, 0], [3, 2, 1, 0]],\n",
    "                            sigma_units=['vox'] * 3,\n",
    "                            shrink_factors=[[2, 1], [2, 1], [8, 4, 2, 1]],\n",
    "                            use_estimate_learning_rate_once = [True ,True, True],\n",
    "                            use_histogram_matching=True,\n",
    "\n",
    "                            winsorize_lower_quantile=0.005,\n",
    "                            winsorize_upper_quantile=0.995,\n",
    "                            write_composite_transform=True,\n",
    "                            terminal_output='file'),\n",
    "               name='antsreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize subject to template normalization\n",
    "def plot_normalization_overlay(in_file, sub, sess, brain_template):\n",
    "\n",
    "    import nibabel as nb\n",
    "    from nilearn.plotting import plot_stat_map\n",
    "    \n",
    "    # Load GM probability map of TPM.nii\n",
    "    img = nb.load(brain_template)\n",
    "    GM_template = nb.Nifti1Image(img.get_fdata(), img.affine, img.header)\n",
    "    \n",
    "    title_text = 'sub: %s - sess: %s' % (sub, sess)\n",
    "\n",
    "    # Plot subject brain on template\n",
    "    out_file = in_file.replace('.nii.gz', '_overlay.svg')\n",
    "    plot_stat_map(in_file, title=title_text, colorbar=False, threshold='auto',\n",
    "                  bg_img=brain_template.replace('brain', 'T1'),\n",
    "                  display_mode='z', cut_coords=range(-30, 46, 15),\n",
    "                  output_file=out_file, annotate=False)\n",
    "\n",
    "    return out_file\n",
    "\n",
    "vis_norm = Node(Function(input_names=['in_file', 'sub', 'sess', 'brain_template'],\n",
    "                         output_names=['out_file'],\n",
    "                         function=plot_normalization_overlay),\n",
    "                name='vis_norm')\n",
    "vis_norm.inputs.brain_template = brain_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize brain segmentation\n",
    "def plot_segmentation(n4, segments, sub, sess):\n",
    "\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    from nilearn.plotting import plot_stat_map\n",
    "    from nilearn.image import coord_transform\n",
    "    from matplotlib.pyplot import cm\n",
    "    \n",
    "    # Plot GM and WM segmentation\n",
    "    title_text = 'sub: %s - sess: %s' % (sub, sess)\n",
    "    gm = segments[0][0]\n",
    "    wm = segments[1][0]\n",
    "\n",
    "    # Get good cut coordinates\n",
    "    img_gm = nb.load(gm)\n",
    "    idx = np.sort(img_gm.get_fdata().nonzero()[-1])\n",
    "    vox_ids = np.linspace(idx[0], idx[-1], num=10,\n",
    "                          endpoint=True).astype('int')[2:-2]\n",
    "    cut_ids = [int(coord_transform(0, 0, r, img_gm.affine)[-1])\n",
    "               for r in vox_ids]\n",
    "\n",
    "    # Create segmentation figure\n",
    "    out_file = n4.replace('.nii.gz', '_overlay.svg')\n",
    "    display = plot_stat_map(\n",
    "        gm, cmap=cm.magma, dim=1, colorbar=False, annotate=False, bg_img=n4,\n",
    "        threshold=0.5, display_mode='z', cut_coords=cut_ids, title=title_text);\n",
    "    display.add_overlay(wm, threshold=0.5, cmap=cm.hsv)\n",
    "    display.savefig(out_file)\n",
    "    display.close()\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "vis_segm = Node(Function(input_names=['n4', 'segments', 'sub', 'sess'],\n",
    "                         output_names=['out_file'],\n",
    "                         function=plot_segmentation),\n",
    "                name='vis_segm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Input & Output Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over subject and session id\n",
    "infosource = Node(IdentityInterface(fields=['subject_id', 'session_id']),\n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subject_id', subject_list),\n",
    "                        ('session_id', session_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input file location\n",
    "anat_file = opj('sub-{subject_id}', 'ses-{session_id}', 'anat',\n",
    "                'sub-{subject_id}_ses-{session_id}_%s.nii.gz' % T1_id)\n",
    "templates = {'anat': anat_file}\n",
    "\n",
    "selectfiles = Node(SelectFiles(templates, base_directory='/data'),\n",
    "                   name='selectfiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save relevant outputs in a datasink\n",
    "datasink = Node(DataSink(base_directory=exp_dir,\n",
    "                         container=out_dir),\n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the following naming substitutions for the datasink\n",
    "substitutions = [('_session_id_%s_subject_id_%s/' % (sess, sub),\n",
    "                  'sub-%s/ses-%s_' % (sub, sess))\n",
    "                 for sess in session_list\n",
    "                 for sub in subject_list]\n",
    "substitutions += [('sub-%s_ses-%s' % (sub, sess), '')\n",
    "                  for sess in session_list\n",
    "                  for sub in subject_list]\n",
    "substitutions += [('_%s_ROI_corrected' % T1_id, ''),\n",
    "                  ('_.nii.gz', '_T1w_corrected.nii.gz'),\n",
    "                  ('c1', 'seg_gm'),\n",
    "                  ('c2', 'seg_wm'),\n",
    "                  ('c3', 'seg_csf'),\n",
    "                  ('c4', 'seg_skull'),\n",
    "                  ('c5', 'seg_head'),\n",
    "                  ('seg_gm_maths_dil', 'brainmask'),\n",
    "                  ('__maths' , '_brain'),\n",
    "                  ('__overlay' , '_segmentation')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Preprocessing Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anatomical preprocessing workflow\n",
    "preproc_anat = Workflow(name='preproc_anat')\n",
    "preproc_anat.base_dir = work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes to workflow and connect them\n",
    "preproc_anat.connect([(infosource, selectfiles, [('subject_id', 'subject_id'),\n",
    "                                                 ('session_id', 'session_id')]),\n",
    "\n",
    "                      # Main part of workflow\n",
    "                      (selectfiles, reorient, [('anat', 'in_file')]),\n",
    "                      (reorient, cropFOV, [('out_file', 'in_file')]),\n",
    "                      (cropFOV, n4, [('out_roi', 'input_image')]),\n",
    "                      (n4, gunzip, [('output_image', 'in_file')]),\n",
    "                      (gunzip, segment, [('out_file', 'channel_files')]),\n",
    "                      (segment, brainmask, [\n",
    "                          (('native_class_images', get_class0), 'in_file'),\n",
    "                          (('native_class_images', get_additional_args), 'args')]),\n",
    "                      (n4, extract_brain, [('output_image', 'in_file')]),\n",
    "                      (brainmask, correct_mask, [('out_file', 'in_file')]),\n",
    "                      (correct_mask, extract_brain, [('out_file', 'in_file2')]),\n",
    "                      (extract_brain, antsreg, [('out_file', 'moving_image')]),\n",
    "\n",
    "                      # Store main results in datasink\n",
    "                      (n4, datasink, [('output_image', 'preproc_anat.@n4')]),\n",
    "                      (segment, datasink, [\n",
    "                          ('native_class_images', 'preproc_anat.@segment')]),\n",
    "                      (correct_mask, datasink, [('out_file', 'preproc_anat.@mask')]),\n",
    "                      (extract_brain, datasink, [('out_file', 'preproc_anat.@brain')]),\n",
    "                      (antsreg, datasink, [\n",
    "                          ('warped_image', 'preproc_anat.@warped_image'),\n",
    "                          ('inverse_warped_image', 'preproc_anat.@inverse_warped_image'),\n",
    "                          ('composite_transform', 'preproc_anat.@transform'),\n",
    "                          ('inverse_composite_transform', 'preproc_anat.@inverse_transform')]),\n",
    "\n",
    "                      # Create and save visual outputs\n",
    "                      (n4, vis_segm, [('output_image', 'n4')]),\n",
    "                      (infosource, vis_segm, [('subject_id', 'sub'),\n",
    "                                              ('session_id', 'sess')]),\n",
    "                      (segment, vis_segm, [('native_class_images', 'segments')]),\n",
    "\n",
    "                      (antsreg, vis_norm, [('warped_image', 'in_file')]),\n",
    "                      (infosource, vis_norm, [('subject_id', 'sub'),\n",
    "                                              ('session_id', 'sess')]),\n",
    "\n",
    "                      (vis_norm, datasink, [('out_file', 'viz_anat.@vis_norm')]),\n",
    "                      (vis_segm, datasink, [('out_file', 'viz_anat.@vis_segm')]),\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preproc_anat output graph\n",
    "preproc_anat.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph in the notebook\n",
    "from IPython.display import Image\n",
    "Image(filename=opj(preproc_anat.base_dir, 'preproc_anat', 'graph.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow in sequential mode\n",
    "preproc_anat.run('Linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save workflow graph visualizations in datasink\n",
    "preproc_anat.write_graph(graph2use='flat', format='svg', simple_form=True)\n",
    "preproc_anat.write_graph(graph2use='colored', format='svg', simple_form=True)\n",
    "\n",
    "from shutil import copyfile\n",
    "copyfile(opj(preproc_anat.base_dir, 'preproc_anat', 'graph.svg'),\n",
    "         opj(exp_dir, out_dir, 'preproc_anat', 'graph.svg'))\n",
    "copyfile(opj(preproc_anat.base_dir, 'preproc_anat', 'graph_detailed.svg'),\n",
    "         opj(exp_dir, out_dir, 'preproc_anat', 'graph_detailed.svg'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Created Visualizations in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the segmentation (segmentation overlayed on T1)\n",
    "for sub in subject_list:\n",
    "    for sess in session_list:\n",
    "        display(SVG(opj(exp_dir, out_dir, 'viz_anat', 'sub-%s' % sub,\n",
    "                        'ses-%s_segmentation.svg' % sess)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the normalization (normalized subject overlayed on template)\n",
    "for sub in subject_list:\n",
    "    for sess in session_list:\n",
    "        display(SVG(opj(exp_dir, out_dir, 'viz_anat', 'sub-%s' % sub,\n",
    "                        'ses-%s_transform_Warped_overlay.svg' % sess)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
